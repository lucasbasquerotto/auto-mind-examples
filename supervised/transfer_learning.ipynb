{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning for Computer Vision Tutorial\n",
    "\n",
    "Based on the tutorial: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "This notebook provides an introduction to transfer learning for computer vision using PyTorch. It demonstrates how to leverage pre-trained models to classify images of ants and bees from the Hymenoptera dataset.\n",
    "\n",
    "The dataset is loaded using a custom [HymenopteraData](../datasets/hymenoptera_data.py) class, which organizes the data into training and validation sets. These sets are then loaded using `DataLoader` with a specified batch size.\n",
    "\n",
    "A pre-trained ResNet18 model is loaded using `torchvision.models`, and the final fully connected layer is replaced to match the number of classes in the Hymenoptera dataset. The model is trained using the SGD optimizer with momentum and a cross-entropy loss function. A learning rate scheduler (`StepLR`) is used to adjust the learning rate at regular intervals.\n",
    "\n",
    "The training loop iterates over the dataset for a specified number of epochs, updating the model parameters to minimize the loss. After each epoch, the model is evaluated on the validation set to measure its accuracy. The evaluation loop computes the accuracy by comparing the model's predictions with the true labels.\n",
    "\n",
    "Additionally, the notebook includes code to save the trained model's state dictionary to a file and load it back for inference. This allows for the model to be reused without retraining.\n",
    "\n",
    "The notebook concludes with a section on visualizing the model's prediction on a validation image, providing a qualitative assessment of the model's performance. In fact, the image is not an ant or a bee, it's a butterfly. The model was trained to classify ants or bees, so it classified the butterfly as a bee, probably because it's more similar (it has wings, for example). According to the path of the image (it's in the `bees` folder), the model classified correctly (among the options). This is the same validation image used in the original tutorial.\n",
    "\n",
    "Most of the boilerplate for the training is handled by the manager class. This includes printing metrics during training and periodically saving the model, allowing training to be resumed from the last checkpoint.\n",
    "\n",
    "The executor `GeneralBatchExecutor` is the default and simplest executor that expects a tensor as input, runs the model with that input, and returns the output. A custom evaluator, `MyEvaluator`, was defined to get the path of an image as input, retrieve the image, transform it into a tensor, run the model with this input tensor, and obtain the insect class from the output. The evaluator then displays the image along with the predicted class.\n",
    "\n",
    "A custom metrics class, `MyMetrics`, was defined to display 6 predictions on images from the validation dataset after the model was trained. A metrics class can define data to be persisted along with the model weights as the result of the `run` method, in a dictionary containing only primitive data types, dictionaries, and lists that can be serialized and parsed directly. This specific class (`MyMetrics`) does not need to store any data and was used solely to plot the images, which are included in the PDF saved at `REPORT_PATH`.\n",
    "\n",
    "More metrics classes can be seen at [lib/metrics.py](../lib/metrics.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'transfer_learning'\n",
    "SAVE_PATH = f'data/test/train/{NAME}-checkpoint.pth'\n",
    "REPORT_PATH = f'data/test/train/{NAME}-report.pdf'\n",
    "DATA_PATH = 'data/hymenoptera_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "  sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from src.datasets.hymenoptera_data import HymenopteraData\n",
    "\n",
    "data = HymenopteraData(root_path=DATA_PATH)\n",
    "datasets = data.datasets\n",
    "\n",
    "print(\n",
    "    \"Loading HymenopteraData\",\n",
    "    len(datasets.train) if isinstance(datasets.train, typing.Sized) else None,\n",
    "    len(datasets.validation or []) if isinstance(datasets.validation, typing.Sized) else None,\n",
    "    len(datasets.test or []) if isinstance(datasets.test, typing.Sized) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = dict(\n",
    "    train=datasets.train,\n",
    "    val=datasets.validation,\n",
    ")\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x],\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "    ) for x in ['train', 'val']\n",
    "}\n",
    "dataset_sizes = data.dataset_sizes\n",
    "class_names = data.class_names\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning the ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(weights='IMAGENET1K_V1')\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from auto_mind.supervised.data import MinimalFullState\n",
    "from src.lib.metrics import MetricsItemPlotter, MetricsCalculatorParams\n",
    "\n",
    "class MyMetrics(MetricsItemPlotter[dict[str, None]]):\n",
    "    def __init__(self, name: str, num_images=6):\n",
    "        super().__init__(name=name)\n",
    "        self.num_images = num_images\n",
    "        self.model: torch.nn.Module | None = None\n",
    "\n",
    "    def run(self, params: MetricsCalculatorParams) -> dict[str, None]:\n",
    "        self.model = params.model\n",
    "        return dict()\n",
    "\n",
    "    def plot(self, info: MinimalFullState, metric: dict[str, None], figsize: tuple[float, float] | None) -> list[Figure]:\n",
    "        model = self.model\n",
    "        assert model is not None\n",
    "        figs = self.visualize_model(model, figsize=figsize)\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "        return figs\n",
    "\n",
    "    def visualize_model(self, model: torch.nn.Module, figsize: tuple[float, float] | None) -> list[Figure]:\n",
    "        num_images = self.num_images\n",
    "        was_training = model.training\n",
    "        model.eval()\n",
    "        images_so_far = 0\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        figs = [fig]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                for j in range(inputs.size()[0]):\n",
    "                    images_so_far += 1\n",
    "                    ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                    ax.axis('off')\n",
    "                    ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
    "                    imshow(inputs.cpu().data[j])\n",
    "\n",
    "                    if images_so_far == num_images:\n",
    "                        model.train(mode=was_training)\n",
    "                        return figs\n",
    "                    else:\n",
    "                        img = plt.gcf()\n",
    "                        figs.append(img)\n",
    "            model.train(mode=was_training)\n",
    "\n",
    "        return figs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_mind import supervised\n",
    "from auto_mind.supervised.handlers import GeneralBatchExecutor, GeneralBatchAccuracyCalculator, Evaluator\n",
    "from src.lib.metrics import MetricsListPlotter, MainMetrics, MetricsFileDirectPlotter\n",
    "\n",
    "class MyEvaluator(Evaluator[str, None]):\n",
    "    def run(self, params) -> None:\n",
    "        model = params.model\n",
    "        img_path = params.input\n",
    "        self.visualize_model_predictions(model, img_path)\n",
    "\n",
    "    def visualize_model_predictions(self, model: torch.nn.Module, img_path: str):\n",
    "        img = Image.open(img_path)\n",
    "        img: typing.Any = data.data_transforms['val'](img)\n",
    "        input: torch.Tensor = img\n",
    "        input = input.unsqueeze(0)\n",
    "        input = input.to(device)\n",
    "\n",
    "        outputs = model(input)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        ax = plt.subplot(2,2,1)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Predicted: {class_names[preds[0]]}')\n",
    "        imshow(input.cpu().data[0])\n",
    "\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "\n",
    "manager = supervised.Manager(\n",
    "    data_params=supervised.ManagerDataParams(\n",
    "        train_dataloader=dataloaders['train'],\n",
    "        validation_dataloader=dataloaders['val'],\n",
    "        test_dataloader=None,\n",
    "    ),\n",
    "    model_params=supervised.ManagerModelParams(\n",
    "        model=model_ft,\n",
    "        criterion=criterion,\n",
    "        executor=GeneralBatchExecutor(),\n",
    "        use_best=True,\n",
    "    ),\n",
    "    optimizer_params=supervised.ManagerOptimizerParams(\n",
    "        optimizer=optimizer_ft,\n",
    "        scheduler=exp_lr_scheduler,\n",
    "        train_early_stopper=None,\n",
    "        test_early_stopper=None,\n",
    "    ),\n",
    "    metrics_params=supervised.ManagerMetricsParams(\n",
    "        evaluator=MyEvaluator(),\n",
    "        accuracy_calculator=GeneralBatchAccuracyCalculator(),\n",
    "        metrics_calculator=MetricsFileDirectPlotter(\n",
    "            plotter=MetricsListPlotter(items=[\n",
    "                MainMetrics(name=NAME),\n",
    "                MyMetrics(name=f\"{NAME}_view\", num_images=6),\n",
    "            ]),\n",
    "            file_path=REPORT_PATH,\n",
    "        ),\n",
    "        batch_interval=False,\n",
    "        default_interval=1,\n",
    "    ),\n",
    "    config=supervised.ManagerConfig(\n",
    "        save_path=SAVE_PATH,\n",
    "        random_seed=0,\n",
    "        train_hook=None,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.train(epochs=25)\n",
    "info = manager.info()\n",
    "assert info is not None\n",
    "print(f'Best val Acc: {info.train_results.best_accuracy:4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on custom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.evaluate(f'{data.data_dir}/val/bees/72100438_73de9f17af.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
